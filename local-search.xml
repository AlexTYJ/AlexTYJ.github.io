<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>HuBert论文阅读</title>
    <link href="/2025/02/19/HuBert%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2025/02/19/HuBert%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<figure><img src="/images/HuBert_1.png" alt="HuBert示意图" /><figcaption aria-hidden="true">HuBert示意图</figcaption></figure><h1 id="概述">概述</h1><ul><li>作用：从无监督数据中学习隐层表示。</li><li>端口：输入为音频，输出为隐层表示。</li></ul><h1 id="训练过程">训练过程：</h1><ol type="1"><li>利用Acoustic Unit Discovery System得到label</li><li>通过HuBERT从mask之后的输入中得到隐层表示z</li><li>计算label和预测之间的loss</li></ol><h1 id="细节">细节</h1><h2 id="acoustic-unit-discovery">Acoustic Unit Discovery</h2><p>可以理解为语音离散化。</p><p>一些记号：</p><p>T个frame的语音 $ X = [x_1,..,x_T] $。Acoustic UnitDiscovery模型输出的hidden units为 $ h(X)=Z=[z_1,..,z_T]$，其中 <spanclass="math inline">\(z_t \in [C]\)</span>是一个C-class的变量。h是一个非监督的聚类模型，如k-means on MFCC。</p><h2 id="mask">Mask</h2><p>使用了和wav2vec 2类似的方法，首先选择 <spanclass="math inline">\(p%\)</span>time-steps作为开始序号，然后从各个序号后面数 <spanclass="math inline">\(l\)</span> 个steps作为要mask的区域。</p><p>假设<span class="math inline">\(M \subset [T]\)</span>为要mask的区域， <span class="math inline">\(\tilde{X}\)</span>表示被mask之后的输入，定义在mask区域上的entropy-loss为：</p><p><span class="math display">\[L_m(f;X,M,Z)= \sum_{t\in M}logp_f(z_t|\tilde{X},t)\]</span></p><p>相应的定义不在mask区域上的enrtopy-loss：</p><p><span class="math display">\[L_u(f;X,M,Z)= \sum_{t\notin M}logp_f(z_t|\tilde{X},t)\]</span></p><p>最终的loss为：</p><p><span class="math display">\[L = \alpha L_m + (1-\alpha)L_u\]</span></p><p>loss公式中，<span class="math inline">\(p_f\)</span>的公式如下；</p><p><span class="math display">\[p_f^{(k)}(c | \tilde{X}, t) = \frac{\exp(\text{sim}(A^{(k)} o_t,e_c)/\tau )}{\sum\limits_{c&#39; =1}^{C} \exp(\text{sim}(A^{(k)} o_t,e_{c&#39;})/\tau )}\]</span></p><p>其中 <span class="math inline">\(A^{(k)}\)</span>是第k个聚类的投影矩阵，乘以 <span class="math inline">\(o_t\)</span>之后变成C-class的离散变量，其中 <span class="math inline">\([o_1, ...,o_T]\)</span> 为Bert的输出。 <span class="math inline">\(e_c\)</span> 是<span class="math inline">\(c\)</span> 的嵌入向量，<spanclass="math inline">\(sim(·,·)\)</span>是两个向量之间的余弦相似度。<span class="math inline">\(\tau\)</span>是logit scaling factor。</p><p>注意这几个变量分别代表什么。我们可以从两条路径来分析</p><ol type="1"><li><p><strong>音频通过Acoustic Unit Discovery模型，得到codewords <spanclass="math inline">\([z_1,..,z_T]\)</span>，这是一组离散的类别。每一个类别<span class="math inline">\(c\)</span> 我们赋予一个嵌入向量，这就是<spanclass="math inline">\(e_c\)</span>，这是标签生成的路径。</strong></p></li><li><p><strong>音频通过HuBert之后得到 <span class="math inline">\([o_1,..., o_T]\)</span>，乘以投影矩阵 <spanclass="math inline">\(A\)</span>，计算和标签的相似度。</strong></p></li></ol><h2 id="cluster-ensembles">Cluster Ensembles</h2><p>k-means根据初始值和k值的不同，其表现也会大不相同。因此作者采用多个不同参数的k-means进行学习，这就是ClusterEnsembles。设用 <spanclass="math inline">\(Z^{(k)}\)</span>表示第k个聚类模型生成的sequence。故此时：</p><p><span class="math display">\[L_m(f;X,\{Z^{(k)}\}_k,M)=\sum_{t\in M} \sum_{k} logp_f^{k}(z_t^{k}|\tilde{X},t)\]</span></p><h2 id="iterative-refinement-of-cluster-assignments">IterativeRefinement of Cluster Assignments</h2><p>虽然可以直接在MFCCs这样的acousticfeatures上直接得到label，但随着学习的进行，这种label显得太过粗糙。因此，在学习进行到一定程度时，我们在模型学习到的表示上重新学习聚类模型来替代之前的聚类模型，提高了模型的精度。</p>]]></content>
    
    
    
    <tags>
      
      <tag>语音技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zipformer论文阅读</title>
    <link href="/2025/02/19/Zipformer%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2025/02/19/Zipformer%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>语音技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VietASR论文阅读</title>
    <link href="/2025/02/19/VietASR%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2025/02/19/VietASR%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="概述">概述</h1><p>VietASR是一个针对小语种的ASRPipeline，结合了HuBert和Zipformer，<strong>本质是HuBert对ASR的适配</strong>。</p><h1 id="改动">改动</h1><ol type="1"><li><p>HuBert使用Fbank直接进行掩码，替代音频+CNN。</p></li><li><p>回顾，HuBert中</p></li></ol><p><span class="math display">\[L_m(f;X,M,Z)= \sum_{t\in M}logp_f(z_t|\tilde{X},t)\]</span></p><p><span class="math display">\[p_f^{(k)}(c | \tilde{X}, t) = \frac{\exp(\text{sim}(A^{(k)} o_t,e_c)/\tau )}{\sum\limits_{c&#39; =1}^{C} \exp(\text{sim}(A^{(k)} o_t,e_{c&#39;})/\tau )}\]</span></p><p>其中，</p><ul><li><p>$ X = [x_1,..,x_T] $ 为T个frame的语音输入。</p></li><li><p>$ Z=[z_1,..,z_T] 为 $Acoustic Unit Discovery模型输出的hiddenunits。</p></li><li><p><span class="math inline">\(z_t \in [C]\)</span>是一个C-class的变量，为语音的离散表示。</p></li><li><p><spanclass="math inline">\(h\)</span>是一个非监督的聚类模型，如k-means onMFCC。</p></li><li><p><spanclass="math inline">\(f\)</span>是HuBert预训练模型。</p></li><li><p><span class="math inline">\(A^{(k)}\)</span>是第k个聚类的投影矩阵，乘以 <span class="math inline">\(o_t\)</span>之后变成C-class的离散变量。</p></li><li><p><span class="math inline">\([o_1, ..., o_T]\)</span>为Bert的输出。</p></li><li><p><span class="math inline">\(e_c\)</span> 是 <spanclass="math inline">\(c\)</span> 的嵌入向量。</p></li><li><p><span class="math inline">\(sim(·,·)\)</span>是两个向量之间的余弦相似度。</p></li><li><p><span class="math inline">\(\tau\)</span> 是logit scalingfactor。</p></li></ul><p>而VietASR修改了余弦相似度，变为：</p><p><span class="math display">\[f(\tilde{X}, c) = - \sum_{t \in \text{masked}} \log \frac{\exp(z_tc_t)}{\sum_{i=1}^C \exp(z_{t,i})} \tag{1}\]</span></p><p><span class="math display">\[o = \text{encoder}(\tilde{X}) = (o_1, o_2, \dots, o_T) \tag{2}\]</span></p><p><span class="math display">\[z_t = A o_t / \tau = (z_{t1}, z_{t2}, \dots, z_{tC}) \tag{3}\]</span></p><p>其中，<span class="math inline">\(X_e\)</span>表示带掩码的输入，<span class="math inline">\(c\)</span>表示簇（cluster）标签，<span class="math inline">\(A\)</span>表示投影矩阵，<span class="math inline">\(\tau\)</span> 为温度参数。</p><h1 id="pipeline">Pipeline</h1><ol type="1"><li><p>在小规模有监督数据上训练一个Zipformer ASR模型，使用RNN-Tloss。</p></li><li><p>对训练好的Zipformer的encoder输出应用k-means，作为HuBert标签。</p></li><li><p>使用上面的标签进行HuBert训练，采用cross-entropy优化。</p></li><li><p>使用pruned RNNT loss对预训练的encoder微调。</p></li></ol><h1 id="section"></h1>]]></content>
    
    
    
    <tags>
      
      <tag>语音技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阿拉伯语ASR</title>
    <link href="/2025/01/20/%E9%98%BF%E6%8B%89%E4%BC%AF%E8%AF%ADASR/"/>
    <url>/2025/01/20/%E9%98%BF%E6%8B%89%E4%BC%AF%E8%AF%ADASR/</url>
    
    <content type="html"><![CDATA[<p>挑战：</p><ul><li>Language Variants:Modern Standard Arabic(MSA), ClassicalArabic(CA，古兰经), and Dialectal Arabic(DA，方言)</li><li>Dialectal Variations：不同地区的方言</li><li>Code-Switching (CS) ：夹杂法文和英文<br /></li><li>Non-Standardized Orthography: DA没有一个uniform orthography</li><li>Annotated Data：缺少标注数据</li></ul>]]></content>
    
    
    <categories>
      
      <category>语音技术</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>阿拉伯语数据集</title>
    <link href="/2025/01/19/%E9%98%BF%E6%8B%89%E4%BC%AF%E8%AF%AD%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2025/01/19/%E9%98%BF%E6%8B%89%E4%BC%AF%E8%AF%AD%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1 id="casablanca">Casablanca</h1><p>论文：https://anthropology/2024.emnlp-main.1211.pdf</p><p>优势：全人工标注（最大的全监督阿拉伯方言数据集）</p><ul><li><p>时长：48h</p></li><li><p>方言：8种（ALG, EGY, JOR, MOR, UAE, PAL, MAU,YEM），8个标签</p></li><li><p>Segmentation：全人工标注</p></li><li><p>Transcription：全人工标注</p></li><li><p>code-switching ：英文、法文（加音译）</p></li></ul><h1 id="qasr">QASR</h1><p>论文：https://arxiv.org/abs/2106.13000</p><ul><li><p>时长：2000h 新闻频道</p></li><li><p>lightly supervisedtranscriptions（训练集中文本为转录的文本，不完全准确，并非人工标注）</p></li><li><p>采样率：16kHz</p></li><li><p>包含语言学驱动的分段（linguistically motivatedsegmentation）、标点符号（punctuation）、说话者信息（speaker informationamong others）</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>语音技术</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>语音基础知识</title>
    <link href="/2025/01/19/%E8%AF%AD%E9%9F%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2025/01/19/%E8%AF%AD%E9%9F%B3%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p>Whisper：弱监督方法。将数据集从4h做到了68h。模型仅仅是Transformer模型。</p>]]></content>
    
    
    <categories>
      
      <category>语音技术</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/01/17/hello-world/"/>
    <url>/2025/01/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <ahref="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <ahref="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>补码再思考</title>
    <link href="/2024/01/18/complement/"/>
    <url>/2024/01/18/complement/</url>
    
    <content type="html"><![CDATA[<p>  我曾在很多课程中学习过补码的知识。然而，大多数时候我受到的教育都是机械地接受:<strong>正数和0的补码就是该数字本身再补上最高比特0。负数的补码则是将其绝对值按位取反再加1。补码可以避免+0和-0的歧义。</strong>但是为什么要这么定义，以及它是如何避免+0和-0的，很多地方都没有解释。本文通过另一种看待补码的角度，尝试解释上述问题。</p>  首先，我们回顾原码的定义：<center><strong>原码是指一个二进制数左边加上符号位后所得到的码</strong></center><p>  由于原码是强行添加的符号位，因此<strong>符号位本身并没有权重</strong>。然而，数学知识告诉我们，在一个正常的进制中，每个位上都应该有某个权重。因此，原码在数学上是<strong>不完备的</strong>，势必会产生一些问题。而这个问题在这里就体现为+0和-0。</p><p>  那么事情就变得很清晰了：我们需要给符号位也赋予一个权重。</p><p>  我们采用如下定义：将第N位的权重定义为<spanclass="math inline">\(-2^{(N-1)}\)</span>,第i (i&lt;N)位的权重定义为<span class="math inline">\(-2^{(i-1)}\)</span>。</p><p>  好了，这样我们的符号位也有了权重。但是，为什么是这个权重？我们可以来看看这样定义会发生什么。</p><p>  我们以一个四位二进制数1101为例。当它作为无符号普通二进制数时，1101=13。当它作为补码时，1101=-3。现在我断言，它们在进行运算的时候，作用是相同的。为什么呢？这是因为四位二进制补码的表示范围是<spanclass="math inline">\([-2^{(4-1)},2^{(4-1)-1}]=[-8,7]\)</span>,这是一个长度为16的区间，也就是说，由于溢出的原因，所有得到的结果都要<strong>模16</strong>到[-8,7]这个区间中，所以-3就等于+13。这样，补码就巧妙地将带符号的二进制数中的<strong>负数转化为了正数</strong>，从而可以正常的进行二进制计算，而且更加符合加法器的原理。</p><p>  现在我们来看看0的问题。让我们来看看1101加几等于0。由于模了16，所以16=0。所以1101+0011=10000=0000。而这个0011，也就是1101的相反数。这就是本文最开始的经验性定义的由来——因为我们要凑10000，所以把正数取反相加，就是1111，再加1，就可以完美产生10000这个数。因此，一个负数的补码，就是它对应的正数取反加1。</p><p>  看到这里，你应该知道了补码的本质优势————可以通过模运算的性质，简单地将加法运算扩展到负数，而不需要特殊的硬件电路或逻辑。</p><p>  最后，我还很好奇，为什么反码的英文是“1'scomplement”，补码的英文是“2'scomplement”。关于这方面的中文资料很少。知乎用户 <span class="citation"data-cites="前端西瓜哥">@前端西瓜哥</span> 在他的知乎文章<ahref="https://zhuanlan.zhihu.com/p/498147694">补码到底是什么？</a>中认为： &gt;补码原意是“2的补数”。这个命名虽然没有描述补码的定义，但它描述了补码的一个特性：一个补码可以通过被<spanclass="math inline">\(2^w\)</span>减去，得到它的相反数，即<spanclass="math inline">\(-x=2^w-x\)</span>。</p><p>  我认为这种说法有待商榷，因为以此类推，因为反码是1'scomplement，所以一个反码可以通过被1减去，得到它的相反数。而这显然与反码的定义相冲突。</p><p>  还有一种说法是ChatGPT说的，它说反码只做了一个操作，涉及到1个值，所以是1'scomplement。补码因为还要+1，涉及到2个值，所以是2'scomplement。我认为这种说法也很牵强。总之我没有在中文互联网查到让我满意的答案。欢迎读者查阅相关英文文献并和我交流！</p>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
    </categories>
    
    
    <tags>
      
      <tag>basic</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
